# Ollama server URL (OpenAI-compatible endpoint)
OLLAMA_URL=http://localhost:11434/v1

# Model to use
OLLAMA_MODEL=qwen2.5:7b
